# åœ¨ 4090 ä¸Š Finetune Hunyuan3D è¸©å‘æŒ‡å—

> RTX 4090: 24GB VRAM, Ada Lovelace æ¶æ„, åŸç”Ÿæ”¯æŒ BF16/FP16

---

## ğŸ”¥ é—®é¢˜ä¸€è§ˆ

| é—®é¢˜ | ç—‡çŠ¶ | æ ¹å›  |
|------|------|------|
| OOM | `CUDA out of memory` | 3.1B å‚æ•° + AdamW åƒçˆ†æ˜¾å­˜ |
| Loss å¡æ­» | è®­ç»ƒ 1500 æ­¥ loss ä¸€ç›´ ~1.95 | ä»å¤´è®­ç»ƒï¼ŒæœªåŠ è½½é¢„è®­ç»ƒæƒé‡ |
| Mesh ä¸ºç©º | `Surface level must be within volume data range` | Token ä¸å¯¹é½ / æ¨¡å‹æ²¡å­¦åˆ°ä¸œè¥¿ |
| NaN çˆ†ç‚¸ | `has_nan=True` | æƒé‡æŸåæˆ–ç²¾åº¦æº¢å‡º |

---

## ğŸ’¥ å‘ 1: OOM

**åŸå› åˆ†æ**ï¼š

```
æ¨¡å‹å‚æ•°: 3.1B (float32 â‰ˆ 12GB)
AdamW çŠ¶æ€: 2x å‚æ•°é‡ (momentum + variance) â‰ˆ 24GB
æ¿€æ´»å€¼: å–å†³äº batch size å’Œåºåˆ—é•¿åº¦
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ€»è®¡: è¿œè¶… 24GB
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```yaml
# 1. LoRA - åªè®­ç»ƒ 0.1% å‚æ•°
lora_config:
  rank: 16
  target_modules: ["to_q", "to_k", "to_v", "out_proj"]

# 2. Gradient Checkpointing - ç”¨è®¡ç®—æ¢æ˜¾å­˜
denoiser_cfg:
  params:
    gradient_checkpointing: true

# 3. å‡å°ç‚¹äº‘è§„æ¨¡
pc_size: 8192  # é»˜è®¤ 16384
```

**æ˜¾å­˜å¯¹æ¯”**ï¼š

| é…ç½® | æ˜¾å­˜å ç”¨ |
|------|----------|
| å…¨é‡å¾®è°ƒ | ğŸ’€ OOM |
| + LoRA | ~18GB |
| + Gradient Checkpointing | ~14GB |

---

## ğŸ’¥ å‘ 2: Loss å¡ä½ä¸åŠ¨

**ç—‡çŠ¶**ï¼š
```
loss=1.95, loss=1.94, loss=1.95...  # æ°¸è¿œåœ¨ 1.9x å¾˜å¾Š
```

**æ ¹å› **: é…ç½®æ–‡ä»¶é‡Œ `denoiser_cfg` æ²¡æœ‰ `from_pretrained`ï¼Œç›¸å½“äºä»å¤´è®­ç»ƒ 3.1B å‚æ•°

**ä¿®å¤**ï¼š
```yaml
denoiser_cfg:
  target: hy3dshape.models.denoisers.hunyuandit.HunYuanDiTPlain
  from_pretrained: tencent/Hunyuan3D-2.1  # ğŸ‘ˆ å¿…é¡»åŠ è¿™è¡Œ
```

**æ­£å¸¸ loss æ›²çº¿**ï¼š
```
step 0:    ~2.0
step 500:  ~1.6
step 1000: ~1.4  âœ… åœ¨ä¸‹é™
```

---

## ğŸ’¥ å‘ 3: Token é•¿åº¦ä¸åŒ¹é…

**ç—‡çŠ¶**ï¼š
```
ValueError: Surface level must be within volume data range.
# Grid logits: min=-1.00, max=-0.98 (å…¨è´Ÿï¼Œä¸åŒ…å« 0)
```

**æ ¹å› **: DINO è¾“å‡º token æ•° â‰  DiT æœŸæœ›çš„ `text_len`

**è®¡ç®—å…¬å¼**ï¼š
```python
# DINO-v2 patch size = 14
num_tokens = (image_size // 14) ** 2 + 2  # +2 for [CLS] + [REG]

# 384 â†’ (384/14)Â² + 2 = 27Â² + 2 = 731 â‰ˆ 730
# 518 â†’ (518/14)Â² + 2 = 37Â² + 2 = 1371 â‰ˆ 1370
```

**å¯¹é½è§„åˆ™**ï¼š

| image_size | text_len | çŠ¶æ€ |
|------------|----------|------|
| 384 | 730 | âœ… |
| 518 | 1370 | âœ… (å®˜æ–¹é¢„è®­ç»ƒ) |
| 384 | 1370 | âŒ ä¸åŒ¹é… |
| 518 | 730 | âŒ ä¸åŒ¹é… |

**æ¨è**: ä½¿ç”¨å®˜æ–¹é…ç½® `image_size=518 + text_len=1370`

---

## ğŸ’¥ å‘ 4: Mesh ç”Ÿæˆä¸ºç©º

**è°ƒè¯•æ–¹æ³•**ï¼š

åœ¨ `pipelines.py` æ·»åŠ ï¼š
```python
print(f"[DEBUG] cond['main'].shape = {cond['main'].shape}")
print(f"[DEBUG] Expected text_len: {self.model.text_len}")
```

åœ¨ `autoencoders/model.py` æ·»åŠ ï¼š
```python
print(f"[DEBUG] Grid logits: min={grid_logits.min():.4f}, max={grid_logits.max():.4f}")
print(f"[DEBUG] mc_level=0.0 éœ€è¦åœ¨æ­¤èŒƒå›´å†…")
```

**å¥åº·è¾“å‡º**ï¼š
```
cond['main'].shape = torch.Size([2, 1370, 1024])  # 1370 = text_len âœ…
Expected text_len: 1370 âœ…
Grid logits: min=-1.03, max=1.03  # åŒ…å« 0 âœ…
```

**å¼‚å¸¸è¾“å‡º**ï¼š
```
Grid logits: min=-1.00, max=-0.98  # å…¨è´Ÿï¼Œä¸åŒ…å« 0 âŒ
```

---

## ğŸ› ï¸ å®Œæ•´å¯ç”¨é…ç½®

```yaml
# hunyuandit-finetuning-4090-24gb.yaml æ ¸å¿ƒé…ç½®

training:
  steps: 6000
  use_amp: true
  amp_type: "bf16"  # 4090 åŸç”Ÿæ”¯æŒ
  base_lr: 1e-5     # LoRA ç”¨å°å­¦ä¹ ç‡

dataset:
  params:
    pc_size: 8192
    image_size: 518  # ğŸ‘ˆ å¿…é¡»å’Œ text_len å¯¹åº”

model:
  params:
    lora_config:
      rank: 16
      target_modules: ["to_q", "to_k", "to_v", "out_proj"]
    
    denoiser_cfg:
      from_pretrained: tencent/Hunyuan3D-2.1  # ğŸ‘ˆ å…³é”®
      params:
        gradient_checkpointing: true
        text_len: 1370  # ğŸ‘ˆ å¿…é¡»å’Œ image_size å¯¹åº”
```

---

## ğŸ“Š TensorBoard ç›‘æ§

```bash
tensorboard --logdir=output_folder/dit/xxx/log/tensorboard --port=6006 --bind_all
```

å…³æ³¨æŒ‡æ ‡ï¼š
- `train/simple`: åº”è¯¥ç¨³æ­¥ä¸‹é™
- `val/simple`: éªŒè¯é›† loss
- æ¯ 500 æ­¥æŸ¥çœ‹ `log/infer/` ä¸‹çš„ `.glb` æ–‡ä»¶

---

## ğŸ¯ å¿«é€Ÿæ£€æŸ¥æ¸…å•

```bash
# è®­ç»ƒå‰ç¡®è®¤
â–¡ from_pretrained å·²é…ç½®
â–¡ image_size (518) å’Œ text_len (1370) å¯¹åº”
â–¡ lora_config å·²å¯ç”¨
â–¡ gradient_checkpointing: true
â–¡ peft åº“å·²å®‰è£…: pip install peft

# è®­ç»ƒä¸­è§‚å¯Ÿ
â–¡ Loss åœ¨ä¸‹é™ (ä¸æ˜¯å¡åœ¨ 1.9x)
â–¡ æ²¡æœ‰ NaN è­¦å‘Š
â–¡ æ˜¾å­˜å ç”¨ < 20GB

# æ¨ç†éªŒè¯
â–¡ cond shape å’Œ text_len åŒ¹é…
â–¡ Grid logits èŒƒå›´åŒ…å« 0
â–¡ .glb æ–‡ä»¶æˆåŠŸç”Ÿæˆ
```

---

## ğŸ’¡ ç¡¬ä»¶çŸ¥è¯†è¡¥å……

**RTX 4090 è§„æ ¼**ï¼š
- VRAM: 24GB GDDR6X
- Tensor Cores: ç¬¬4ä»£ (æ”¯æŒ FP8/BF16/TF32)
- å¸¦å®½: 1TB/s

**ç²¾åº¦é€‰æ‹©**ï¼š
| ç²¾åº¦ | æ˜¾å­˜ | é€Ÿåº¦ | ç¨³å®šæ€§ |
|------|------|------|--------|
| FP32 | 1x | 1x | æœ€ç¨³å®š |
| BF16 | 0.5x | ~1.5x | æ¨è |
| FP16 | 0.5x | ~1.5x | å¯èƒ½æº¢å‡º |

> BF16 æŒ‡æ•°ä½å’Œ FP32 ç›¸åŒï¼Œä¸æ˜“æº¢å‡ºï¼Œ4090 åŸç”Ÿæ”¯æŒï¼Œä¼˜å…ˆé€‰æ‹©

---

*Last updated: 2026-01*
